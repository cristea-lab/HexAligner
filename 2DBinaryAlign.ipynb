{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b50fbc4",
   "metadata": {},
   "source": [
    "# 0. Description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c744b9c",
   "metadata": {},
   "source": [
    "This is a jupyter notebook file (python script) that aligns two binary images that are misaligned by unknown amount of offset in the horiztonal and/or vertical directions. This script will overlay the given two images in all possible ways, pixel by pixel, and select the best aligned images. It assumes the images are in the same scale of units, in the same orientation, and expected to have some degree of overlap.\n",
    "\n",
    "This script returns a dataframe of pixel coordinates of both images (labelled such that the pixel source is clear) and the aligned images\n",
    "\n",
    "For the current version, the script is hard-coded such that one of the image is exactly 2408 pixels by 2408 pixels and named the two images to be 'cell' and 'collagen', but the script can be amended for a general case. This repository will further be improved such that it will include an example toy images and be more generalizable for use.\n",
    "\n",
    "This python code was ran in version 3.7.4."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "postal-france",
   "metadata": {},
   "source": [
    "# 1. Set up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "million-plastic",
   "metadata": {},
   "source": [
    "## 1.1 libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "romance-bosnia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "print version\n",
      "3.7.4 (default, Sep 11 2019, 11:24:51) \n",
      "[GCC 6.2.0]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(\"print version\")\n",
    "print(sys.version)\n",
    "\n",
    "import os\n",
    "import time\n",
    "# insert your path to python libraries here\n",
    "sys.path.insert(1, \"/path/to/lib/\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import subprocess\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from functools import partial\n",
    "from functools import wraps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5acbc9",
   "metadata": {},
   "source": [
    "## 1.2 variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59b59fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert your path to project here\n",
    "path_project = '/path/to/project/'\n",
    "\n",
    "path_image_cell = f'{path_project}data/image_cell_231019/png_converted/'\n",
    "path_image_collagen = f'{path_project}data/image_collagen_230904/'\n",
    "\n",
    "path_df_collagen = f'{path_project}data/df_collagen_231023/'\n",
    "path_df_collagen_mod = f'{path_project}data/df_collagen_modified_231019/'\n",
    "vec_filenames_df_collagen = os.listdir(f'{path_df_collagen}')\n",
    "\n",
    "path_df_cell = f'{path_project}data/df_cell_231023/'\n",
    "\n",
    "path_map = f'{path_project}data/'\n",
    "file_map = f'{path_map}core_patient_mapping.csv'\n",
    "\n",
    "file_df_cell = f'{path_project}data/df_cell.csv'\n",
    "df_cell = pd.read_csv(file_df_cell)\n",
    "df_cell['id'] = df_cell['tumor_ids'].astype(str) + '_' + df_cell['core_ids'].astype(str)\n",
    "\n",
    "path_plot_overlap = f\"{path_project}plot/overlap_231030/\"\n",
    "path_plot_overlap_shifted = f\"{path_project}plot/overlap_shifted_231030/\"\n",
    "path_df_collagen_modified = f\"{path_project}data/df_collagen_modified_231030/\"\n",
    "path_map_leftover = f'{path_project}script/overlay_collagen_cell/'\n",
    "\n",
    "colormap_scatter = {'cell': 'blue', 'collagen': 'red'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ede4733",
   "metadata": {},
   "source": [
    "## 1.3 function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "lovely-combine",
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeit(func):\n",
    "    \"\"\"Decorator to measure execution time of a function.\"\"\"\n",
    "    @wraps(func)\n",
    "    def timeit_wrapper(*args, **kwargs):\n",
    "        start_time = time.perf_counter()\n",
    "        result = func(*args, **kwargs)\n",
    "        end_time = time.perf_counter()\n",
    "        total_time = end_time - start_time\n",
    "        print(f'\\nFunction <{func.__name__}> Took {total_time:.4f} seconds')\n",
    "        return result\n",
    "    return timeit_wrapper\n",
    "\n",
    "def translate_R1(c, min_input, max_input, min_output, max_output):\n",
    "    \"\"\"Translates a value from one range to another.\"\"\"\n",
    "    return ((c - min_input) / (max_input - min_input) * (max_output - min_output) + min_output)\n",
    "\n",
    "@timeit\n",
    "def get_df_map():\n",
    "    \"\"\"Reads and processes mapping data from a CSV file.\"\"\"\n",
    "    df_map = pd.read_csv(file_map)\n",
    "    df = df_map\n",
    "\n",
    "    # Melt the DataFrame to reshape data\n",
    "    df_map_melted = pd.melt(df, id_vars=['TumorID', 'TMA', 'Block_ID_cust', 'Variant'],\n",
    "                            value_vars=['Core 1', 'Core 2'], \n",
    "                            var_name='CoreType', value_name='Value')\n",
    "\n",
    "    # Drop rows with NaN in the 'Value' column\n",
    "    df_map_melted = df_map_melted.dropna(subset=['Value'])\n",
    "\n",
    "    # Clean up and format data in 'CoreType' and 'Value' columns\n",
    "    df_map_melted['CoreType'] = df_map_melted['CoreType'].str.replace(' ', '')\n",
    "    df_map_melted = df_map_melted.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "    df_map_melted['CoreID'] = '1,' + df_map_melted['Value'].astype(str)\n",
    "    df_map_melted['CoreID_modified'] = (df_map_melted['TMA'].astype(str) + '.' +\n",
    "                                        df_map_melted['Variant'].astype(str) + '_' +\n",
    "                                        df_map_melted['CoreID'].astype(str))\n",
    "    df_map_melted = df_map_melted[['TumorID', 'CoreID_modified']]\n",
    "    return df_map_melted\n",
    "\n",
    "def get_filename(index_image):\n",
    "    \"\"\"Retrieves the filename based on image index and mapping data.\"\"\"\n",
    "    for index_temp, row in df_filenames_png[['key_PNG', 'filename']].iloc[(index_image):(index_image + 1)].iterrows():\n",
    "        i = row['key_PNG']\n",
    "        df_match = df_map_melted[df_map_melted['CoreID_modified'] == i]\n",
    "\n",
    "        if df_match.shape[0] == 0:\n",
    "            print(f'<get_filename> WARNING: no match for {i}; skip')\n",
    "        elif df_match.shape[0] != 1:\n",
    "            print(f'<get_filename> ERROR: more than one match')\n",
    "        else:\n",
    "            print(f'<get_filename> SUCCESS: one match for {i}')\n",
    "            i_tumor_id, i_core_id = df_match[['TumorID', 'CoreID_modified']].iloc[0].values\n",
    "            i_filename_cell = row['filename']\n",
    "            i_filename_collagen = re.sub(r\"_phenotype_map-\\d+\", \"\", i_filename_cell)\n",
    "            i_filename_output = f'{i_tumor_id}_{i_core_id}'\n",
    "            return i_filename_cell, i_filename_collagen, i_filename_output\n",
    "\n",
    "def fn_reconstruct(df, img=None, bool_color_white=True, bool_save=False, path_save=None, name_plot=None):\n",
    "    \"\"\"Reconstructs an image from a DataFrame of pixel coordinates and RGB values.\"\"\"\n",
    "    # Create a blank image array\n",
    "    if img is None:\n",
    "        reconstructed_img = np.zeros((max(df['x']) + 1, max(df['y']) + 1, 3), dtype=np.uint8)\n",
    "        print(f\"<fn_reconstruct> image size: {max(df['x']) + 1, max(df['y']) + 1}\")\n",
    "    else:\n",
    "        reconstructed_img = np.zeros((img.size[1], img.size[0], 3), dtype=np.uint8)\n",
    "        print(f'<fn_reconstruct> image size: {img.size[1], img.size[0]}')\n",
    "\n",
    "    # Fill the image array with pixel values\n",
    "    if bool_color_white:\n",
    "        reconstructed_img[df['x'].values, df['y'].values] = [255, 255, 255]\n",
    "    else:\n",
    "        reconstructed_img[df['x'].values, df['y'].values] = df[['red', 'green', 'blue']].values\n",
    "\n",
    "    # Display the reconstructed image\n",
    "    plt.imshow(reconstructed_img)\n",
    "    plt.show()\n",
    "\n",
    "    # Save the image if required\n",
    "    if bool_save and path_save and name_plot:\n",
    "        file_path = os.path.join(path_save, f\"{name_plot}.png\")\n",
    "        plt.savefig(file_path)\n",
    "    plt.close()\n",
    "\n",
    "def fn_image_to_df(file_image):\n",
    "    \"\"\"Converts an image file into a DataFrame containing pixel coordinates and RGB values, excluding white pixels.\"\"\"\n",
    "    # Open the image and convert it to RGB\n",
    "    colourImg = Image.open(file_image)\n",
    "    colourPixels = colourImg.convert(\"RGB\")\n",
    "\n",
    "    # Get image dimensions\n",
    "    width, height = colourImg.size\n",
    "\n",
    "    # Reshape the RGB data array to match image dimensions\n",
    "    colourArray = colourArray.reshape((height, width, 3))\n",
    "\n",
    "    # Create an array of pixel indices\n",
    "    indicesArray = np.moveaxis(np.indices((height, width)), 0, 2)\n",
    "\n",
    "    # Combine the indices and color data, and reshape into a 2D array\n",
    "    allArray = np.dstack((indicesArray, colourArray)).reshape((-1, 5))\n",
    "\n",
    "    # Create a DataFrame from the array\n",
    "    df = pd.DataFrame(allArray, columns=[\"y\", \"x\", \"red\", \"green\", \"blue\"])\n",
    "\n",
    "    # Exclude white pixels (where R=G=B=255)\n",
    "    df_subset = df[~((df['red'] == 255) & (df['green'] == 255) & (df['blue'] == 255))]\n",
    "    return colourImg, df_subset\n",
    "        \n",
    "# get a dataframe df_filenames_png which has \n",
    "def fn_get_df_filenames_png(path_image_cell):\n",
    "    \"\"\"Generates a DataFrame from filenames in the specified directory using a regex pattern.\"\"\"\n",
    "    filenames_png = os.listdir(path_image_cell)\n",
    "\n",
    "    # Regex pattern to capture the required portions of the filename\n",
    "    pattern = r\"HTMA_(\\d{3})\\.(\\d)_Core\\[(\\d+,\\d+,\\d+)\\]\"\n",
    "\n",
    "    # Lists to store the extracted values\n",
    "    three_digits = []\n",
    "    single_digit = []\n",
    "    comma_separated_digits = []\n",
    "\n",
    "    # Iterate through each filename and extract the desired information\n",
    "    for filename in filenames_png:\n",
    "        match = re.search(pattern, filename)\n",
    "        if match:\n",
    "            three_digits.append(match.group(1))\n",
    "            single_digit.append(match.group(2))\n",
    "            comma_separated_digits.append(match.group(3))\n",
    "        else:\n",
    "            print('no match for:', filename)\n",
    "\n",
    "    # Convert the lists to a DataFrame\n",
    "    df_filenames_png = pd.DataFrame({\n",
    "        'ThreeDigits': three_digits,\n",
    "        'SingleDigit': single_digit,\n",
    "        'CommaSeparatedDigits': comma_separated_digits\n",
    "    })\n",
    "\n",
    "    # Create 'key_PNG' column by combining the captured patterns\n",
    "    df_filenames_png['key_PNG'] = (df_filenames_png['ThreeDigits'].astype(str) + \n",
    "                                   '.' + \n",
    "                                   df_filenames_png['SingleDigit'].astype(str) + \n",
    "                                   '_' + \n",
    "                                   df_filenames_png['CommaSeparatedDigits'].astype(str))\n",
    "    df_filenames_png['filename'] = filenames_png\n",
    "\n",
    "    return(df_filenames_png)\n",
    "\n",
    "# Create a DataFrame from the list of filenames\n",
    "def fn_create_df_map(df_cell, path_df_cell, path_df_collagen, df_filenames_png):\n",
    "    \"\"\"Creates a DataFrame mapping cell and collagen files to their respective data.\"\"\"\n",
    "    df_image_cell_files = pd.DataFrame({'file_cell': os.listdir(path_df_cell)})\n",
    "    df_image_cell_files['file_cell'] = df_image_cell_files['file_cell'].str.replace('.tsv$', '', regex=True)\n",
    "\n",
    "    df_image_collagen_files = pd.DataFrame({'file_collagen': os.listdir(path_df_collagen)})\n",
    "    df_image_collagen_files['file_collagen'] = df_image_collagen_files['file_collagen'].str.replace('.tsv$', '', regex=True)\n",
    "\n",
    "    df_map = pd.merge(\n",
    "        pd.merge(df_cell[['id', 'core_ids']].drop_duplicates(), \n",
    "                 df_image_cell_files, \n",
    "                 how = 'left', left_on = 'id', right_on = 'file_cell'), \n",
    "        df_image_collagen_files,\n",
    "        how = 'left', left_on = 'id', right_on = 'file_collagen')\n",
    "    df_map_temp = pd.merge(\n",
    "        df_map,\n",
    "        df_filenames_png[['key_PNG', 'filename']],\n",
    "        how = 'left', left_on = 'core_ids', right_on = 'key_PNG'\n",
    "    )\n",
    "\n",
    "    df_map_temp['filename_cell'] = df_map_temp['filename']\n",
    "    df_map_temp['filename_collagen'] = df_map_temp['filename'].str.replace('_phenotype_map-14.png', '.png', regex=True)\n",
    "    df_map_temp.drop('filename', axis = 1, inplace = True)\n",
    "    return(df_map_temp)\n",
    "\n",
    "def create_pixel_offset_tuples(width, height):\n",
    "    \"\"\"Generates a dictionary of pixel offset tuples for given width and height.\"\"\"\n",
    "    if (width > 2408) or (height > 2408):\n",
    "        print(f\"<create_pixel_offset_tuples> wrong width and height: {width} {height}\")\n",
    "        \n",
    "    # Subtracting 2409 from A and B\n",
    "    n_pixel_offset_x = 2409 - width\n",
    "    n_pixel_offset_y = 2409 - height\n",
    "    \n",
    "    # Creating vec_offset_x and vec_offset_y arrays\n",
    "    vec_offset_x = np.arange(n_pixel_offset_x)\n",
    "    vec_offset_y = np.arange(n_pixel_offset_y)\n",
    "    \n",
    "    # Creating all combinations of pairs from vec_offset_x and vec_offset_y\n",
    "    pixel_pairs = [(x, y) for x in vec_offset_x for y in vec_offset_y]\n",
    "    \n",
    "    # Creating a dictionary with tuples as keys and empty values\n",
    "    pixel_dict = {pair: None for pair in pixel_pairs}\n",
    "    \n",
    "    return pixel_dict\n",
    "def save_df(df, filename_output, TYPE=None):\n",
    "    \"\"\"Saves the given DataFrame to a TSV file based on the specified TYPE.\"\"\"\n",
    "    if TYPE == 'collagen':\n",
    "        # Construct the filename for collagen and save the DataFrame\n",
    "        file_df_collagen = f'{path_df_collagen}{filename_output}.tsv'\n",
    "        df.to_csv(file_df_collagen, sep='\\t', index=None)\n",
    "    elif TYPE == 'cell':\n",
    "        # Construct the filename for cell and save the DataFrame\n",
    "        file_df_cell = f'{path_df_cell}{filename_output}.tsv'\n",
    "        df.to_csv(file_df_cell, sep='\\t', index=None)\n",
    "    else:\n",
    "        print(f'<save_df> ERROR: TYPE must be collagen or cell')\n",
    "\n",
    "def count_overlap(df1, df2):\n",
    "    \"\"\"Counts the number of overlapping pixels between two DataFrames.\"\"\"\n",
    "    df_merge_temp = pd.merge(df1[['x', 'y']], df2[['x', 'y']], \n",
    "                             how = 'outer', left_on = ['x', 'y'], right_on = ['x', 'y'], indicator = True)\n",
    "    return(sum(df_merge_temp['_merge'] == 'both'))\n",
    "\n",
    "def compute_overlap(keys_subset, df_image_collagen, df_image_cell):\n",
    "    \"\"\"Computes the overlap of pixels between collagen and cell images for each offset key.\"\"\"\n",
    "    result = []\n",
    "    for keys in keys_subset:\n",
    "        x, y = keys\n",
    "        df_temp = pd.DataFrame({'x': df_image_collagen['x'] + x, 'y': df_image_collagen['y'] + y})\n",
    "        overlap = count_overlap(df_image_cell, df_temp)\n",
    "        result.append((keys, overlap))\n",
    "    return result\n",
    "\n",
    "from functools import partial\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import numpy as np\n",
    "\n",
    "@timeit\n",
    "def parallel_compute_overlap(dict_offset, df_image_collagen, df_image_cell, num_splits=10):\n",
    "    \"\"\"Performs parallel computation of pixel overlap between collagen and cell images.\"\"\"\n",
    "    print(f'<parallel_compute_overlap> trying {len(dict_offset.keys())} combinations')\n",
    "    \n",
    "    # Convert the keys to a NumPy array for proper splitting\n",
    "    keys_array = np.array(list(dict_offset.keys()), dtype=object)\n",
    "\n",
    "    # Splitting the keys for parallel processing\n",
    "    keys_split = np.array_split(keys_array, num_splits)\n",
    "    \n",
    "    # Creating partial function for compute_overlap with fixed arguments\n",
    "    partial_func = partial(compute_overlap, df_image_collagen=df_image_collagen, df_image_cell=df_image_cell)\n",
    "    \n",
    "    # Using ProcessPoolExecutor for parallel processing\n",
    "    with ProcessPoolExecutor() as executor:\n",
    "        results = list(executor.map(partial_func, keys_split))\n",
    "    \n",
    "    # Updating dict_offset with results from parallel computation\n",
    "    for subset in results:\n",
    "        for keys, overlap in subset:\n",
    "            dict_offset[tuple(keys)] = overlap\n",
    "        \n",
    "    return dict_offset\n",
    "\n",
    "def transform_df_image_collagen(df_image_collagen, df_image_cell, df_cell_subset, \n",
    "                                bool_save=False, \n",
    "                                path_save=path_df_collagen_modified,\n",
    "                                name_df=None):\n",
    "    \"\"\"Transforms the coordinates of collagen DataFrame based on cell DataFrame and optional saving.\"\"\"\n",
    "    # Calculating minimum and maximum coordinates for cell image and cell DataFrame\n",
    "    min_x_cell_image = min(df_image_cell['x'])\n",
    "    max_x_cell_image = max(df_image_cell['x'])\n",
    "    min_y_cell_image = min(df_image_cell['y'])\n",
    "    max_y_cell_image = max(df_image_cell['y'])\n",
    "\n",
    "    min_x_cell_df = min(df_cell_subset['X'])\n",
    "    max_x_cell_df = max(df_cell_subset['X'])\n",
    "    min_y_cell_df = min(df_cell_subset['Y'])\n",
    "    max_y_cell_df = max(df_cell_subset['Y'])\n",
    "\n",
    "    # Applying translation to y and x coordinates\n",
    "    df_image_collagen['y_trans'] = df_image_collagen['y'].apply(\n",
    "        lambda c: translate_R1(c, min_y_cell_image, max_y_cell_image, min_y_cell_df, max_y_cell_df)\n",
    "    )\n",
    "    df_image_collagen['x_trans'] = df_image_collagen['x'].apply(\n",
    "        lambda c: translate_R1(c, min_x_cell_image, max_x_cell_image, min_x_cell_df, max_x_cell_df)\n",
    "    )\n",
    "\n",
    "    # Creating a modified DataFrame with translated coordinates\n",
    "    df_image_collagen_mod = df_image_collagen[['x_trans', 'y_trans']]\n",
    "    df_image_collagen_mod.columns = ['x', 'y']\n",
    "\n",
    "    # Optionally save the modified DataFrame\n",
    "    if bool_save:\n",
    "        file_df_image_collagen_mod = f'{path_save}{name_df}.tsv'\n",
    "        df_image_collagen_mod[['x', 'y']].to_csv(file_df_image_collagen_mod, index=False, sep='\\t')\n",
    "\n",
    "    return df_image_collagen_mod\n",
    "\n",
    "@timeit\n",
    "def fn_align(index_core, df_map):\n",
    "    \"\"\"Aligns and visualizes the overlap between collagen and cell images for a given core index.\"\"\"\n",
    "    # Retrieve the specific row from df_map based on the index\n",
    "    row = df_map.iloc[index_core]\n",
    "    ID = row['id']\n",
    "    \n",
    "    print(f'<fn_align> starting with index: {index_core}, ID: {ID}')\n",
    "    \n",
    "    # Constructing file paths\n",
    "    filename_df_image_collagen = f\"{path_df_collagen}{ID}.tsv\"\n",
    "    filename_df_image_cell = f\"{path_df_cell}{ID}.tsv\"\n",
    "    filename_image_collagen = f\"{path_image_collagen}{row['filename_collagen']}\"\n",
    "    file_paths = [filename_df_image_collagen, filename_df_image_cell, filename_image_collagen]\n",
    "\n",
    "    # Checking if all required files exist\n",
    "    if not all(os.path.isfile(path) for path in file_paths):\n",
    "        print(f\"<fn_align> some files don't exist for {ID}\")\n",
    "        return\n",
    "\n",
    "    # Loading the data from files\n",
    "    df_cell_subset = df_cell[df_cell['id'] == ID]\n",
    "    df_image_collagen = pd.read_csv(filename_df_image_collagen, sep='\\t')[['x', 'y']]\n",
    "    df_image_cell = pd.read_csv(filename_df_image_cell, sep='\\t')[['x', 'y']]\n",
    "    image_collagen = Image.open(filename_image_collagen)\n",
    "\n",
    "    width, height = image_collagen.size\n",
    "\n",
    "    # Aligning and processing images if size is not standard\n",
    "    if (width != 2408) or (height != 2408):\n",
    "        dict_offset = create_pixel_offset_tuples(width, height)\n",
    "        print(f'<fn_align> image_collagen size: {width} x {height}')\n",
    "        \n",
    "        updated_dict_offset = parallel_compute_overlap(dict_offset, df_image_collagen, df_image_cell)\n",
    "        key_with_highest_value = max(updated_dict_offset, key=updated_dict_offset.get)\n",
    "        print(f\"<fn_align> key with highest value {key_with_highest_value}\")\n",
    "\n",
    "        # Adjusting collagen image coordinates based on the offset\n",
    "        x, y = key_with_highest_value\n",
    "        df_image_collagen['x'] = df_image_collagen['x'] + x\n",
    "        df_image_collagen['y'] = df_image_collagen['y'] + y\n",
    "\n",
    "    # Setting colors for visualization\n",
    "    df_image_collagen[['red', 'green', 'blue']] = [255, 0, 0]\n",
    "    df_image_cell[['red', 'green', 'blue']] = [255, 255, 255]\n",
    "\n",
    "    # Combining and reconstructing the image\n",
    "    df_temp = pd.concat([df_image_collagen, df_image_cell], axis=0)\n",
    "    fn_reconstruct(df_temp, bool_color_white=False, bool_save=True, path_save=path_plot_overlap, name_plot=ID)\n",
    "\n",
    "    # Transforming and saving the modified collagen image\n",
    "    df_image_collagen_modified = transform_df_image_collagen(df_image_collagen, df_image_cell, df_cell_subset, \n",
    "                                                             bool_save=True, path_save=path_df_collagen_modified, name_df=ID)\n",
    "    \n",
    "    # Preparing data for scatter plot\n",
    "    df_cell_subset_temp = df_cell_subset[['X', 'Y']].copy()\n",
    "    df_cell_subset_temp.columns = ['x', 'y']\n",
    "    df_cell_subset_temp['type'] = 'cell'\n",
    "    df_image_collagen_modified = df_image_collagen_modified.copy()\n",
    "    df_image_collagen_modified['type'] = 'collagen'\n",
    "    \n",
    "    # Plotting and saving the scatter plot\n",
    "    df_temp = pd.concat([df_image_collagen_modified, df_cell_subset_temp], axis=0)\n",
    "    colors = df_temp['type'].map(colormap_scatter)\n",
    "    plt.scatter(df_temp['x'], df_temp['y'], color=colors)\n",
    "    plt.savefig(f'{path_plot_overlap_shifted}{ID}.png')\n",
    "    plt.show()\n",
    "\n",
    "def update_map(df_map, vec_completed, bool_save=False, path_save=None, name_df=None):\n",
    "    \"\"\"Updates the mapping DataFrame to exclude completed jobs, with optional saving.\"\"\"\n",
    "    # Merging df_map with completed file list to identify unfinished jobs\n",
    "    df_map_temp = pd.merge(df_map, pd.DataFrame({'file_plot': vec_completed}),\n",
    "                           how='left', left_on='id', right_on='file_plot')\n",
    "    \n",
    "    # Keeping only the rows without matches in vec_completed\n",
    "    result = df_map_temp[df_map_temp['file_plot'].isna()].copy()\n",
    "    \n",
    "    # Dropping the temporary 'file_plot' column\n",
    "    result.drop('file_plot', axis=1, inplace=True)\n",
    "    \n",
    "    # Saving the updated DataFrame if requested\n",
    "    if bool_save:\n",
    "        result.to_csv(f'{path_save}{name_df}.tsv', sep='\\"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442db0fc",
   "metadata": {},
   "source": [
    "# main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab1b608b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_map_melted = get_df_map()\n",
    "df_filenames_png = fn_get_df_filenames_png(path_image_cell)\n",
    "df_map = fn_create_df_map(df_cell, path_df_cell, path_df_collagen, df_filenames_png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f67d2a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting index 13\n"
     ]
    }
   ],
   "source": [
    "for i in range(13, 14):\n",
    "    print(f\"starting index {i}\")\n",
    "    # run functions here\n",
    "    # fn_align(i, df_map)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
